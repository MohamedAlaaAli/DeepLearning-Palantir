{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import Omniglot\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OmniglotFewShot(Dataset):\n",
    "    def __init__(self, root, mode=\"train\", transform=None, n_way=5, k_shots=5, n_query=5):\n",
    "        super(OmniglotFewShot, self).__init__()\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.n_way = n_way\n",
    "        self.k_shots = k_shots\n",
    "        self.n_query = n_query\n",
    "        self.mode = mode\n",
    "        self.data = Omniglot(root=self.root, background=True if self.mode == \"train\" else False, download=True, transform=self.transform)\n",
    "        self.indices_by_class = self._create_indices_by_class()\n",
    "\n",
    "    def _create_indices_by_class(self):\n",
    "        indices_by_class = {}\n",
    "        for idx, (_, label) in enumerate(self.data):\n",
    "            if label not in indices_by_class:\n",
    "                indices_by_class[label] = []\n",
    "            indices_by_class[label].append(idx)\n",
    "        return indices_by_class\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices_by_class)\n",
    "\n",
    "    def __getitem__(self, _):\n",
    "        class_indices = np.random.choice(list(self.indices_by_class.keys()), self.n_way, replace=False)\n",
    "        \n",
    "        support_set = []\n",
    "        query_set = []\n",
    "        support_labels = []\n",
    "        query_labels = []\n",
    "\n",
    "        for class_index in class_indices:\n",
    "            indices = np.random.choice(self.indices_by_class[class_index], self.k_shots + self.n_query, replace=False)\n",
    "            class_support_set_indices = indices[:self.k_shots]\n",
    "            class_query_set_indices = indices[self.k_shots:]\n",
    "\n",
    "            for i in class_support_set_indices:\n",
    "                image, _ = self.data[i]\n",
    "                support_set.append(image)\n",
    "                support_labels.append(class_index)\n",
    "\n",
    "            for i in class_query_set_indices:\n",
    "                image, _ = self.data[i]\n",
    "                query_set.append(image)\n",
    "                query_labels.append(class_index)\n",
    "\n",
    "        # Convert lists to tensors for PyTorch compatibility\n",
    "        support_set = torch.stack(support_set)\n",
    "        query_set = torch.stack(query_set)\n",
    "        support_labels = torch.tensor(support_labels)\n",
    "        query_labels = torch.tensor(query_labels)\n",
    "\n",
    "        return support_set, query_set, support_labels, query_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomRotation90:\n",
    "    def __call__(self, img):\n",
    "        angle = random.choice([0, 90, 180, 270])\n",
    "        return transforms.functional.rotate(img, angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    RandomRotation90(),\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = OmniglotFewShot(root='./data', mode='train', transform=transform, n_way=60, k_shots=5, n_query=5)\n",
    "test_dataset = OmniglotFewShot(root='./data', mode='test', transform=transform, n_way=5, k_shots=5, n_query=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(train_dataset,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[655, 655, 655, 655, 655, 924, 924, 924, 924, 924, 662, 662, 662, 662,\n",
       "         662, 834, 834, 834, 834, 834, 937, 937, 937, 937, 937, 205, 205, 205,\n",
       "         205, 205,  90,  90,  90,  90,  90, 672, 672, 672, 672, 672, 833, 833,\n",
       "         833, 833, 833,  71,  71,  71,  71,  71, 174, 174, 174, 174, 174, 685,\n",
       "         685, 685, 685, 685,  80,  80,  80,  80,  80, 535, 535, 535, 535, 535,\n",
       "         849, 849, 849, 849, 849, 429, 429, 429, 429, 429, 765, 765, 765, 765,\n",
       "         765, 492, 492, 492, 492, 492, 189, 189, 189, 189, 189, 959, 959, 959,\n",
       "         959, 959, 619, 619, 619, 619, 619, 351, 351, 351, 351, 351, 273, 273,\n",
       "         273, 273, 273, 154, 154, 154, 154, 154, 817, 817, 817, 817, 817, 352,\n",
       "         352, 352, 352, 352, 620, 620, 620, 620, 620, 644, 644, 644, 644, 644,\n",
       "         519, 519, 519, 519, 519, 819, 819, 819, 819, 819, 544, 544, 544, 544,\n",
       "         544, 216, 216, 216, 216, 216, 551, 551, 551, 551, 551, 841, 841, 841,\n",
       "         841, 841, 729, 729, 729, 729, 729,  42,  42,  42,  42,  42, 915, 915,\n",
       "         915, 915, 915, 101, 101, 101, 101, 101, 864, 864, 864, 864, 864, 157,\n",
       "         157, 157, 157, 157, 590, 590, 590, 590, 590,  52,  52,  52,  52,  52,\n",
       "         362, 362, 362, 362, 362, 431, 431, 431, 431, 431, 671, 671, 671, 671,\n",
       "         671, 727, 727, 727, 727, 727, 180, 180, 180, 180, 180,  41,  41,  41,\n",
       "          41,  41, 549, 549, 549, 549, 549, 263, 263, 263, 263, 263, 522, 522,\n",
       "         522, 522, 522, 376, 376, 376, 376, 376, 777, 777, 777, 777, 777, 914,\n",
       "         914, 914, 914, 914, 169, 169, 169, 169, 169, 900, 900, 900, 900, 900,\n",
       "         501, 501, 501, 501, 501, 199, 199, 199, 199, 199, 902, 902, 902, 902,\n",
       "         902, 472, 472, 472, 472, 472]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_images(images, num_images=5):\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(num_images * 3, 3))\n",
    "    for i in range(num_images):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(images[i][0], cmap='gray')  \n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "visualize_images(a[0].squeeze(0), num_images=5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_images(a[1].squeeze(0), num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Embedder, self).__init__()\n",
    "        self.in_channels = 1\n",
    "        self.out_channels = 64\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels, self.out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(self.out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(self.out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(self.out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(self.out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.flatten(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Embedder = Embedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Embedder(a[0].squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 64])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 300, 1, 28, 28])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 300, 1, 28, 28])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2]==a[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 300])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Protonet(nn.Module):\n",
    "    def __init__(self, embedder):\n",
    "        super(Protonet, self).__init__()\n",
    "        self.embedder = embedder\n",
    "\n",
    "    def forward(self, support, query, n_way, k_shots):\n",
    "        \"\"\"\n",
    "        Perform the forward pass and compute the prototypes.\n",
    "\n",
    "        Parameters:\n",
    "        - support: The support set.\n",
    "        - query: The query set.\n",
    "        - n_way: The number of classes (ways).\n",
    "        - k_shots: The number of examples per class in the support set.\n",
    "\n",
    "        Returns:\n",
    "        - query_embeddings: The embeddings of the query set.\n",
    "        - prototypes: The class prototypes.\n",
    "        \"\"\"\n",
    "        # Embed support and query sets\n",
    "        print(support.shape)\n",
    "        support_embeddings = self.embedder(support.squeeze(0))\n",
    "        query_embeddings = self.embedder(query.squeeze(0))\n",
    "        \n",
    "        # Calculate the prototypes for each class in the support set\n",
    "        # Reshape support embeddings to [n_way, k_shots, embedding_size] and compute mean across k_shots\n",
    "        prototypes = support_embeddings.view(n_way, k_shots, -1).mean(dim=1)\n",
    "        \n",
    "        return query_embeddings, prototypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Protonet(Embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def protonet_loss(query_embeddings, prototypes, query_labels, n_way):\n",
    "    \"\"\"\n",
    "    Computes the Prototypical Networks loss given embeddings of the query set,\n",
    "    class prototypes, and query labels.\n",
    "\n",
    "    Parameters:\n",
    "    - query_embeddings: The embeddings of the query set.\n",
    "    - prototypes: The class prototypes.\n",
    "    - query_labels: The labels for the query set.\n",
    "    - n_way: The number of classes (ways).\n",
    "\n",
    "    Returns:\n",
    "    - Loss calculated using Negative Log Likelihood.\n",
    "    \"\"\"\n",
    "    # Calculate the Euclidean distance from each query sample to the prototypes\n",
    "    distances = torch.cdist(query_embeddings, prototypes)\n",
    "    \n",
    "    # Convert distances to log probabilities\n",
    "    log_p_y = nn.functional.log_softmax(-distances, dim=1)\n",
    "    \n",
    "    # Calculate and return the loss\n",
    "    loss = nn.functional.nll_loss(log_p_y, query_labels.long())\n",
    "    return loss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
