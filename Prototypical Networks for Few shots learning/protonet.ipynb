{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import Omniglot\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OmniglotFewShot(Dataset):\n",
    "    def __init__(self, root, mode=\"train\", transform=None, n_way=5, k_shots=5, n_query=5):\n",
    "        super(OmniglotFewShot, self).__init__()\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.n_way = n_way\n",
    "        self.k_shots = k_shots\n",
    "        self.n_query = n_query\n",
    "        self.mode = mode\n",
    "        self.data = Omniglot(root=self.root, background=True if self.mode == \"train\" else False, download=True, transform=self.transform)\n",
    "        self.indices_by_class = self._create_indices_by_class()\n",
    "\n",
    "    def _create_indices_by_class(self):\n",
    "        indices_by_class = {}\n",
    "        for idx, (_, label) in enumerate(self.data):\n",
    "            if label not in indices_by_class:\n",
    "                indices_by_class[label] = []\n",
    "            indices_by_class[label].append(idx)\n",
    "        return indices_by_class\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices_by_class)\n",
    "\n",
    "    def __getitem__(self, _):\n",
    "        class_indices = np.random.choice(list(self.indices_by_class.keys()), self.n_way, replace=False)\n",
    "        \n",
    "        support_set = []\n",
    "        query_set = []\n",
    "        support_labels = []\n",
    "        query_labels = []\n",
    "\n",
    "        for class_index in class_indices:\n",
    "            indices = np.random.choice(self.indices_by_class[class_index], self.k_shots + self.n_query, replace=False)\n",
    "            class_support_set_indices = indices[:self.k_shots]\n",
    "            class_query_set_indices = indices[self.k_shots:]\n",
    "\n",
    "            for i in class_support_set_indices:\n",
    "                image, _ = self.data[i]\n",
    "                support_set.append(image.unsqueeze(0))  # Add an extra dimension\n",
    "                support_labels.append(class_index)\n",
    "\n",
    "            for i in class_query_set_indices:\n",
    "                image, _ = self.data[i]\n",
    "                query_set.append(image.unsqueeze(0))  # Add an extra dimension\n",
    "                query_labels.append(class_index)\n",
    "\n",
    "        support_set = torch.stack(support_set, dim=0).reshape(self.n_way, self.k_shots, *image.shape)\n",
    "        query_set = torch.stack(query_set, dim=0).reshape(self.n_way, self.n_query, *image.shape)\n",
    "        support_labels = torch.tensor(support_labels)\n",
    "        query_labels = torch.tensor(query_labels)\n",
    "\n",
    "        support_set = support_set.to(device)\n",
    "        query_set = query_set.to(device)\n",
    "        support_labels = support_labels.to(device)\n",
    "        query_labels = query_labels.to(device)\n",
    "        \n",
    "\n",
    "        return support_set, query_set, support_labels, query_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomRotation90:\n",
    "    def __call__(self, img):\n",
    "        angle = random.choice([0, 90, 180, 270])\n",
    "        return transforms.functional.rotate(img, angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    RandomRotation90(),\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Embedder, self).__init__()\n",
    "        self.in_channels = 1\n",
    "        self.out_channels = 64\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels, self.out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(self.out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(self.out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(self.out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(self.out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.flatten(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Embedder = Embedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embedder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Protonet(nn.Module):\n",
    "    def __init__(self, embedder):\n",
    "        super(Protonet, self).__init__()\n",
    "        self.embedder = embedder\n",
    "\n",
    "    def forward(self, support, query):\n",
    "        \"\"\"\n",
    "        Perform the forward pass and compute the prototypes.\n",
    "\n",
    "        Parameters:\n",
    "        - support: The support set.\n",
    "        - query: The query set.\n",
    "        - n_way: The number of classes (ways).\n",
    "        - k_shots: The number of examples per class in the support set.\n",
    "\n",
    "        Returns:\n",
    "        - query_embeddings: The embeddings of the query set.\n",
    "        - prototypes: The class prototypes.\n",
    "        \"\"\"\n",
    "        # Embed support and query sets\n",
    "        xs = support.squeeze(0)\n",
    "        xq = query.squeeze(0)\n",
    "\n",
    "        n_class  =xs.shape[0]\n",
    "        n_support =xs.shape[1]\n",
    "        n_query = xq.shape[1]\n",
    "\n",
    "        \n",
    "        target_inds = torch.arange(0, n_class).view(n_class, 1, 1).expand(n_class, n_query, 1).long()\n",
    "        target_inds = Variable(target_inds, requires_grad=False).to(device)\n",
    "        x = torch.cat([xs.view(n_class * n_support, *xs.size()[2:]),\n",
    "                       xq.view(n_class * n_query, *xq.size()[2:])], 0)\n",
    "\n",
    "        z = self.embedder.forward(x)\n",
    "        z_dim = z.size(-1)\n",
    "\n",
    "        z_proto = z[:n_class*n_support].view(n_class, n_support, z_dim).mean(1)\n",
    "        zq = z[n_class*n_support:]\n",
    "\n",
    "\n",
    "        dists = torch.cdist(zq, z_proto)\n",
    "\n",
    "        log_p_y = F.log_softmax(-dists, dim=1).view(n_class, n_query, -1)\n",
    "\n",
    "        loss_val = -log_p_y.gather(2, target_inds).squeeze().view(-1).mean()\n",
    "\n",
    "        _, y_hat = log_p_y.max(2)\n",
    "        acc_val = torch.eq(y_hat, target_inds.squeeze()).float().mean()\n",
    "\n",
    "        return loss_val, {\n",
    "            'loss': loss_val.item(),\n",
    "            'acc': acc_val.item()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Protonet(Embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = StepLR(optimizer, step_size=2000, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, test_loader, best_val_loss = float('inf'), best_acc=-float('inf')):\n",
    "    num_epochs = 1000\n",
    "    total_episodes = 0  \n",
    "    patience = 3  \n",
    "    wait = 0  \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  \n",
    "        total_loss = 0.0\n",
    "        total_acc = 0.0\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, desc=f'Training Epoch {epoch + 1}/{num_epochs}', unit='batch')\n",
    "        \n",
    "        for support_set, query_set, support_labels, query_labels in train_pbar:\n",
    "            optimizer.zero_grad()\n",
    "            loss, results = model(support_set, query_set)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_acc += results['acc']\n",
    "\n",
    "            train_pbar.set_postfix({'Loss': loss.item(), 'Accuracy': results['acc']})\n",
    "            \n",
    "            total_episodes += 1  \n",
    "            scheduler.step(total_episodes)  \n",
    "            \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_acc = total_acc / len(train_loader)\n",
    "        print(f'Training Epoch [{epoch + 1}/{num_epochs}], Avg. Loss: {avg_loss:.4f}, Avg. Accuracy: {avg_acc:.4f}')\n",
    "        \n",
    "        # Validation loop\n",
    "        model.eval()  \n",
    "        total_val_loss = 0.0\n",
    "        total_val_acc = 0.0\n",
    "        \n",
    "        val_pbar = tqdm(test_loader, desc=f'Validation Epoch {epoch + 1}/{num_epochs}', unit='batch')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for support_set, query_set, support_labels, query_labels in val_pbar:\n",
    "                loss, results = model(support_set, query_set)\n",
    "                total_val_loss += loss.item()\n",
    "                total_val_acc += results['acc']\n",
    "\n",
    "                val_pbar.set_postfix({'Loss': loss.item(), 'Accuracy': results['acc']})\n",
    "        \n",
    "        avg_val_loss = total_val_loss / len(test_loader)\n",
    "        avg_val_acc = total_val_acc / len(test_loader)\n",
    "        print(f'Validation Epoch [{epoch + 1}/{num_epochs}], Avg. Loss: {avg_val_loss:.4f}, Avg. Accuracy: {avg_val_acc:.4f}')\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_acc = avg_val_acc\n",
    "            wait = 0  \n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(f'Validation loss did not improve for {patience} epochs. Early stopping...')\n",
    "                break\n",
    "        \n",
    "    # Training complete\n",
    "    print('Training complete.')\n",
    "    return best_val_loss, best_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = OmniglotFewShot(root='./data', mode='train', transform=transform, n_way=60, k_shots=5, n_query=5)\n",
    "train_loader = DataLoader(train_dataset,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_dataset = OmniglotFewShot(root='./data', mode='test', transform=transform, n_way=5, k_shots=5, n_query=15)\n",
    "test_loader = DataLoader(test_dataset,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/1000:   0%|          | 0/964 [00:00<?, ?batch/s, Loss=3.59, Accuracy=0.14]/home/mohamed/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:149: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "Training Epoch 1/1000: 100%|██████████| 964/964 [03:20<00:00,  4.81batch/s, Loss=0.291, Accuracy=0.913]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch [1/1000], Avg. Loss: 0.5608, Avg. Accuracy: 0.8498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 1/1000: 100%|██████████| 659/659 [00:21<00:00, 30.78batch/s, Loss=0.104, Accuracy=0.987] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch [1/1000], Avg. Loss: 0.0733, Avg. Accuracy: 0.9783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/1000: 100%|██████████| 964/964 [03:06<00:00,  5.18batch/s, Loss=0.165, Accuracy=0.933] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch [2/1000], Avg. Loss: 0.2116, Avg. Accuracy: 0.9385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 2/1000: 100%|██████████| 659/659 [00:20<00:00, 32.82batch/s, Loss=0.0134, Accuracy=1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch [2/1000], Avg. Loss: 0.0611, Avg. Accuracy: 0.9809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/1000: 100%|██████████| 964/964 [03:04<00:00,  5.21batch/s, Loss=0.196, Accuracy=0.923] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch [3/1000], Avg. Loss: 0.1558, Avg. Accuracy: 0.9527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 3/1000: 100%|██████████| 659/659 [00:19<00:00, 34.50batch/s, Loss=0.0318, Accuracy=0.973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch [3/1000], Avg. Loss: 0.0521, Avg. Accuracy: 0.9837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/1000: 100%|██████████| 964/964 [03:03<00:00,  5.24batch/s, Loss=0.104, Accuracy=0.97]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch [4/1000], Avg. Loss: 0.1348, Avg. Accuracy: 0.9584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 4/1000: 100%|██████████| 659/659 [00:18<00:00, 35.12batch/s, Loss=0.123, Accuracy=0.973] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch [4/1000], Avg. Loss: 0.0572, Avg. Accuracy: 0.9829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/1000: 100%|██████████| 964/964 [03:02<00:00,  5.27batch/s, Loss=0.194, Accuracy=0.933] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch [5/1000], Avg. Loss: 0.1156, Avg. Accuracy: 0.9638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 5/1000: 100%|██████████| 659/659 [00:18<00:00, 35.11batch/s, Loss=0.179, Accuracy=0.973] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch [5/1000], Avg. Loss: 0.0506, Avg. Accuracy: 0.9846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/1000: 100%|██████████| 964/964 [03:02<00:00,  5.27batch/s, Loss=0.104, Accuracy=0.963] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch [6/1000], Avg. Loss: 0.1047, Avg. Accuracy: 0.9670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 6/1000: 100%|██████████| 659/659 [00:18<00:00, 35.37batch/s, Loss=0.101, Accuracy=0.947] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch [6/1000], Avg. Loss: 0.0471, Avg. Accuracy: 0.9856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/1000: 100%|██████████| 964/964 [03:03<00:00,  5.26batch/s, Loss=0.153, Accuracy=0.96]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch [7/1000], Avg. Loss: 0.0966, Avg. Accuracy: 0.9693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 7/1000: 100%|██████████| 659/659 [00:18<00:00, 35.08batch/s, Loss=0.0977, Accuracy=0.987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch [7/1000], Avg. Loss: 0.0496, Avg. Accuracy: 0.9854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/1000: 100%|██████████| 964/964 [03:03<00:00,  5.25batch/s, Loss=0.145, Accuracy=0.96]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch [8/1000], Avg. Loss: 0.0914, Avg. Accuracy: 0.9705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 8/1000: 100%|██████████| 659/659 [00:18<00:00, 35.11batch/s, Loss=0.0132, Accuracy=1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch [8/1000], Avg. Loss: 0.0462, Avg. Accuracy: 0.9859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/1000: 100%|██████████| 964/964 [03:03<00:00,  5.26batch/s, Loss=0.088, Accuracy=0.973] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch [9/1000], Avg. Loss: 0.0875, Avg. Accuracy: 0.9715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 9/1000: 100%|██████████| 659/659 [00:18<00:00, 35.08batch/s, Loss=0.0029, Accuracy=1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch [9/1000], Avg. Loss: 0.0495, Avg. Accuracy: 0.9847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/1000: 100%|██████████| 964/964 [03:01<00:00,  5.30batch/s, Loss=0.0727, Accuracy=0.987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch [10/1000], Avg. Loss: 0.0845, Avg. Accuracy: 0.9723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 10/1000: 100%|██████████| 659/659 [00:18<00:00, 35.39batch/s, Loss=0.0572, Accuracy=0.987] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch [10/1000], Avg. Loss: 0.0525, Avg. Accuracy: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/1000: 100%|██████████| 964/964 [03:01<00:00,  5.30batch/s, Loss=0.121, Accuracy=0.953] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch [11/1000], Avg. Loss: 0.0824, Avg. Accuracy: 0.9731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 11/1000: 100%|██████████| 659/659 [00:18<00:00, 35.56batch/s, Loss=0.0076, Accuracy=1]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch [11/1000], Avg. Loss: 0.0469, Avg. Accuracy: 0.9855\n",
      "Validation loss did not improve for 3 epochs. Early stopping...\n",
      "Training complete.\n",
      "5 way 5 shot results (0.04615281028638108, 0.9858978368986359)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"5 way 5 shot results {train(train_loader, test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()  \n",
    "    total_val_loss = 0.0\n",
    "    total_val_acc = 0.0\n",
    "    num_batches = len(val_loader)\n",
    "    \n",
    "    # Create tqdm progress bar for validation\n",
    "    val_pbar = tqdm(val_loader, desc='Validation', unit='batch')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for support_set, query_set, support_labels, query_labels in val_pbar:\n",
    "            loss, results = model(support_set, query_set)\n",
    "            total_val_loss += loss.item()\n",
    "            total_val_acc += results['acc']\n",
    "\n",
    "            val_pbar.set_postfix({'Loss': loss.item(), 'Accuracy': results['acc']})\n",
    "    \n",
    "    # Calculate average loss and accuracy for the validation set\n",
    "    avg_val_loss = total_val_loss / num_batches\n",
    "    avg_val_acc = total_val_acc / num_batches\n",
    "    \n",
    "    return avg_val_loss, avg_val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 659/659 [00:14<00:00, 44.58batch/s, Loss=0.0776, Accuracy=0.987]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 way 1 shot results (0.16194710969971388, 0.9468487814995877)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset = OmniglotFewShot(root='./data', mode='test', transform=transform, n_way=5, k_shots=1, n_query=15)\n",
    "test_loader = DataLoader(test_dataset,shuffle=True)\n",
    "print(f\"5 way 1 shot results {validate(model, test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 659/659 [00:53<00:00, 12.26batch/s, Loss=0.603, Accuracy=0.787]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 way 1 shot results (0.5185531473214058, 0.8467931410068807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset = OmniglotFewShot(root='./data', mode='test', transform=transform, n_way=20, k_shots=1, n_query=15)\n",
    "test_loader = DataLoader(test_dataset,shuffle=True)\n",
    "print(f\"20 way 1 shot results {validate(model, test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 659/659 [01:07<00:00,  9.78batch/s, Loss=0.0976, Accuracy=0.98] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 way 5 shot results (0.15649693870241435, 0.9539555158347389)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset = OmniglotFewShot(root='./data', mode='test', transform=transform, n_way=20, k_shots=5, n_query=15)\n",
    "test_loader = DataLoader(test_dataset,shuffle=True)\n",
    "print(f\"20 way 5 shot results {validate(model, test_loader)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
